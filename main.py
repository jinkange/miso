try:
    import cv2
    import os
    import numpy as np
    import pytesseract
    from PIL import Image
    import time
    import hashlib
    import shutil
    import subprocess
except Exception as e:
    print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    input("\nğŸ”š í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ë ¤ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")


SCREENSHOT_PATH = "screen.png"
PREVIOUS_SCREENSHOT_PATH = "screen_prev.png"
# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
TARGET_PRICE = int(input("ìµœì†Œ í´ë¦­í•  ê°€ê²©ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 55000): "))

if not os.path.exists(r"C:\Program Files\Tesseract-OCR\tesseract.exe"):
    print("âš ï¸ Tesseractê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
    input("ì•„ë¬´í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”... ")
    exit()
    
# TARGET_PRICE = 50000
TARGET_CLICK_RATIO = (0.534, 0.16)  # í™”ë©´ì˜ ê°€ë¡œ 50%, ì„¸ë¡œ 90%
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
def take_screenshot(save_as=SCREENSHOT_PATH):
    os.system("adb shell screencap -p /sdcard/screen.png")
    os.system(f"adb pull /sdcard/screen.png {save_as}")

def hash_image(image_path):
    with open(image_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

def images_are_same(img1_path, img2_path):
    return hash_image(img1_path) == hash_image(img2_path)

def extract_prices(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    data = pytesseract.image_to_data(gray, lang='kor+eng', output_type=pytesseract.Output.DICT)
    found = []

    for i, text in enumerate(data['text']):
        clean_text = text.replace(",", "").replace("\\", "").replace(" ", "").strip()
        # if "ì›" in clean_text:
        try:
            # '55,000ì›' â†’ 55000
            price_str = ''.join(filter(str.isdigit, clean_text))
            price = int(price_str)
            
            if price >= TARGET_PRICE:
                x = data['left'][i]
                y = data['top'][i]
                found.append((price, x, y))
        except:
            continue
    return found

def click(x, y):
    os.system(f"adb shell input tap {x} {y}")

def get_screen_resolution():
    out = os.popen("adb shell wm size").read()
    # ì˜ˆ: "Physical size: 1080x1920\n"
    if "Physical size:" in out:
        parts = out.strip().split(":")[1].strip().split("x")
        return int(parts[0]), int(parts[1])
    return 1080, 1920  # ê¸°ë³¸ê°’

def click_relative(rx, ry):
    width, height = get_screen_resolution()
    x = int(rx * width)
    y = int(ry * height)
    print(f"ğŸ–± ë¹„ë¡€ í´ë¦­ ìœ„ì¹˜: {x}, {y}")
    click(x, y)

def scroll_down_slow():
    os.system("adb shell input swipe 3 1000 3 650 80")
    os.system("adb shell input swipe 2 1000 2 999 5")
    # os.system("adb shell input swipe 500 1500 500 700 400") 

def preprocess_image_for_ocr(img):
    # HSV ë³€í™˜ìœ¼ë¡œ íŒŒë€ìƒ‰ ë°°ê²½ ê²€ì¶œ
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower_blue = np.array([100, 50, 50])
    upper_blue = np.array([140, 255, 255])
    mask = cv2.inRange(hsv, lower_blue, upper_blue)

    # íŒŒë€ ë°°ê²½ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    blue_part = cv2.bitwise_and(img, img, mask=mask)

    # ê·¸ë ˆì´ ë³€í™˜ í›„ ë°˜ì „ â†’ ê¸€ìê°€ ë°ì•„ì§
    gray = cv2.cvtColor(blue_part, cv2.COLOR_BGR2GRAY)
    inverted = cv2.bitwise_not(gray)

    # ì´ì§„í™”
    _, thresh = cv2.threshold(inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

def extract_text_data(img, lang='kor+eng'):
    processed_img = preprocess_image_for_ocr(img)
    data = pytesseract.image_to_data(
        processed_img,
        lang=lang,
        output_type=pytesseract.Output.DICT
    )
    return data

def find_and_click_text(image_path, target_text, threshold=0.8):
    """
    ì´ë¯¸ì§€ì—ì„œ ì›í•˜ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ìœ„ì¹˜ë¥¼ í´ë¦­
    :param image_path: ì´ë¯¸ì§€ ê²½ë¡œ
    :param target_text: ì°¾ê³  ì‹¶ì€ í•œê¸€ ë˜ëŠ” ë¬¸ìì—´ (ì˜ˆ: "ê²°ì œ")
    :param threshold: OCR ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ 0.8)
    """
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, threshed = cv2.threshold(gray, 160, 255, cv2.THRESH_BINARY)

    # OCR ë°ì´í„° (ì–¸ì–´ kor í¬í•¨)
    data = pytesseract.image_to_data(gray, lang='kor+eng', output_type=pytesseract.Output.DICT)
    words_with_coords = []
    for i, text in enumerate(data['text']):
        clean = text.strip()
        if clean == "":
            continue
        x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
        words_with_coords.append((x, y, w, h, clean))
    # ì¤„ ë‹¨ìœ„ë¡œ ë³‘í•© (Yì¢Œí‘œ ê¸°ì¤€)
    lines = []
    current_line = []
    last_y = None
    for x, y, w, h, text in sorted(words_with_coords, key=lambda item: (item[1], item[0])):
        if last_y is None or abs(y - last_y) < 25:
            current_line.append((x, y, w, h, text))
        else:
            lines.append(current_line)
            current_line = [(x, y, w, h, text)]
        last_y = y
    if current_line:
        lines.append(current_line)

    for i, line in enumerate(lines):
        line_sorted = sorted(line, key=lambda w: w[0])  # x ê¸°ì¤€ ì •ë ¬
        lines[i] = line_sorted
    
    for line in lines:
        line_text = "".join(word[4] for word in line)
        if target_text in line_text:
            print(f"âœ… '{target_text}' ë°œê²¬ëœ ì¤„: {line_text}")
            # í´ë¦­ ì¢Œí‘œ ê³„ì‚° (ì¤‘ê°„ ë‹¨ì–´ ê¸°ì¤€)
            mid_word = line[len(line)//2]
            x_click = mid_word[0] + mid_word[2] // 2
            y_click = mid_word[1] + mid_word[3] // 2
            subprocess.run(["adb", "shell", "input", "tap", str(x_click), str(y_click)])
            return True

    print("âŒ ì›í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return False



def main():
    
    while 1:
        scroll_count = 0
        max_scrolls = 10
        # take_screenshot(PREVIOUS_SCREENSHOT_PATH)

        while scroll_count < max_scrolls:
            take_screenshot(SCREENSHOT_PATH)
            prices = extract_prices(SCREENSHOT_PATH)

            if prices:
                price, x, y = prices[0]
                print(f"âœ… {price}ì› ë°œê²¬, í´ë¦­ ìœ„ì¹˜: ({x},{y})")
                click(x + 50, y + 50)
                # ë‚˜ë¨¸ì§€ ì‘ì—…
                find_and_click_text(SCREENSHOT_PATH, "ë™ë‘ì²œì‹œ")
                click_relative(*TARGET_CLICK_RATIO)
                break

            # ê³„ì† ìŠ¤í¬ë¡¤
            print(f"ğŸ”„ ì¡°ê±´ ë¶ˆì¶©ì¡±. ìŠ¤í¬ë¡¤ {scroll_count + 1}/{max_scrolls}")
            scroll_down_slow()
            scroll_count += 1
            time.sleep(0.1)
            take_screenshot(PREVIOUS_SCREENSHOT_PATH)

            # ì´ì „ í™”ë©´ê³¼ ë™ì¼í•˜ë©´ ë¹„ë¡€ ì¢Œí‘œ í´ë¦­
            if images_are_same(SCREENSHOT_PATH, PREVIOUS_SCREENSHOT_PATH):
                print("ğŸ” ì´ì „ í™”ë©´ê³¼ ë™ì¼: ë” ì´ìƒ ìŠ¤í¬ë¡¤ë˜ì§€ ì•ŠìŒ")
                click_relative(*TARGET_CLICK_RATIO)
                break

        print("â›” ì¡°ê±´ ë§Œì¡± ê°€ê²© ì—†ìŒ. ì¢…ë£Œ ë˜ëŠ” ëŒ€ì²´ ì²˜ë¦¬ í•„ìš”.")
    input("ì•„ë¬´í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”... ")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    input("\nğŸ”š í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ë ¤ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
